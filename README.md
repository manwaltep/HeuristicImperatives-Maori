# Heuristic Imperatives Tikanga Māori: A Revised Framework for Infusing Te Ao Māori Wisdom into Artificial Intelligence
## Artificial Intelligence Alignment Problem (General)

Researchers in the field of AI are focusing on the Artificial Intelligence Alignment Problems to ensure that the development and implementation of AI aligns with the values and interests of humanity.
The Artificial Intelligence Alignment Problems are gaining significant attention as AI technologies advance, highlighting the need to ensure that these systems align with human values, objectives, and ethical norms.

One facet of Artificial Intelligence Alignment Problems is **inner alignment**, which aims to create AI models like GPT-4, Davinci, and others that inherently possess the capacity to comprehend and adhere to human values.
The challenge of **outer alignment**, a key component of Artificial Intelligence Alignment Problems, involves configuring the structures and mechanisms of AI systems in a way that they align seamlessly with human societal values.
Addressing Artificial Intelligence Alignment Problems is critical, not only for ensuring that AI technologies like GPT-4 and Davinci respect and operate within the framework of human values, but also for maintaining trust in AI systems and mitigating potential risks.

Artificial Intelligence Alignment Problems are not just technical obstacles but also ethical dilemmas that need to be navigated carefully, as they involve aligning AI entities and models with human-centric values and considerations.
To find feasible solutions to Artificial Intelligence Alignment Problems, AI developers and ethicists are working hand-in-hand to ensure both the inner and outer alignment of AI systems with human values.
Experts in AI and ethics emphasize that failure to address Artificial Intelligence Alignment Problems can lead to undesirable consequences, potentially causing AI systems to operate counter to human values and societal norms.

Artificial Intelligence Alignment Problems pose a significant challenge to AI developers, who must ensure that AI models and their broader structures remain consistent with human values throughout their development and operational phases.
The focus on Artificial Intelligence Alignment Problems is a testament to the field's commitment to ensuring that the benefits of AI technologies are maximized while minimising potential harms and ethical issues.

**Inner Alignment** discusses how to align an Artificial Intelligence model, such as Curie, Babbage, Davinci, GPT-3.5-turbo, Gpt-4 so forth and so on, to those such as human values.  

**Outter Alignment** discusses how to align the structures and entities of Artificial Intelligence to human values. 

## Artificial Intelligence Alignment Problem (Te Ao Māori)
The Artificial Intelligence Alignment Problems and their relevance to the concern about AI "colonising" Te Reo Maori, the indigenous language of the Maori people of New Zealand, revolve around ensuring that AI systems respect and align with the cultural values, nuances, and specific contexts inherent in this language.

One facet of the issue involves "inner alignment" – ensuring that AI models have an intrinsic understanding and respect for Te Reo Maori, its cultural nuances, and the unique values it embodies. This includes AI being capable of interpreting and using the language in a culturally sensitive and accurate manner.

"Outer alignment" involves shaping AI's structures and mechanisms to align with the societal and cultural values represented by Te Reo Maori. This means that AI systems should be developed and deployed in ways that respect Maori culture and language, rather than imposing a "colonising" influence that could potentially distort or dilute these cultural aspects.

Addressing these AI alignment issues is crucial in mitigating the risk of AI systems inadvertently causing cultural harm, such as misinterpreting, misrepresenting, or erasing important elements of Te Reo Maori and Maori culture.

The concern about AI "colonising" Te Reo Maori underscores the broader need for AI systems to be designed and implemented with a deep understanding and respect for local cultures, languages, and values, a challenge that lies at the heart of the Artificial Intelligence Alignment Problems.

In this context, AI developers and stakeholders have a responsibility to engage with Maori communities, language experts, and cultural advisors to ensure that AI technologies align effectively with Te Reo Maori and do not inadvertently "colonise" or harm this significant cultural heritage.

## Axiomatic Alignment (Te Ao Maori)
In the context of Artificial Intelligence, an axiom is a statement or principle that is accepted as being true without requiring proof, serving as a basis for logical reasoning and further deductions in a particular system of knowledge. axiomatic alignment refers to the process of guiding the behaviour, learning, and decision-making processes of an AI system. 

These axioms act as core values or hard-wired rules that the AI cannot violate, ensuring its actions and decisions align with the desired outcomes or ethical standards established by its designers or stakeholders. Axiomatic alignment is one avenue that may support and address the Artificial Intelligence Alignment Problem, ensuring that AI systems behave in ways that align with human values, safety requirements, and ethical norms. 

Te Reo Maori, is the native language of tangata Māori (Māori people). Te Reo Māori has a rich oral and written tradition that encapsulates Māori history, culture, and values. Te Reo Māori is considered a taonga, or treasure, and efforts have been made to revitalise and see it thrive in New Zealand society. Its unique structure and idioms offer deep insights into the worldview of tangata Māori, making its preservation and respectful usage a matter of cultural significance.

The lack of axioms or logical grounding is the biggest problem with Reinforcement Learning with Human Feedback (RLHF). It's intended that by grounding documents, systems, and processes into axioms establishes a fundamental set of principles or rules that guide the operation, decision-making, and overall function of these entities. 

Here is what this does:

1. **Provides Clear Guidelines:** Axioms offer a clear set of foundational rules or principles that need to be adhered to. This can provide a roadmap for actions and decisions, helping ensure consistency and adherence to the intended purpose or ethical standards.

2. **Facilitates Predictability:** When documents, systems, or processes are grounded in axioms, their behavior or outcomes become more predictable, as they operate based on the predefined axiomatic rules. This can reduce uncertainty and improve reliability.

3. **Ensures Ethical Compliance:** In contexts where the axioms represent ethical norms or societal values, grounding systems in these axioms can help ensure that they operate in an ethically sound and socially responsible manner.

4. **Enhances Transparency and Trust:** Axiomatic principles can be shared with stakeholders, helping them understand how a particular system or process operates or makes decisions. This can foster 

## A framework to embed a 'Tikanga Māori based system' into Artificial Intelligence. 

Emerging out of Heuristic Imperatives, is a project based on the idea of encapsulating axiomatic based values into Artificial Intelligence systems. From which, decisions relating to ethics and logic can start to surface. This revised framework weaves principles into autonomous AI and Large Language Models (LLMs). These re-envisioned principles, provide a starting place to which values inherent in Te Ao Māori can be encapsulated, provide guidance for decision-making, learning, self-evaluation, and cognitive control within AI systems.

A refined set of heuristic imperatives include:
1. **Whakatāharaharatia te mamae** (Reduce and Suffering) in the universe.
2. **Whakapuāwaitia** (Increase Prosperity) in the universe.
3. **Whakawhanaungatanga** (Increase Understanding and Relationships) in the universe.
4. **Tino Rangatiratanga** (Increase Self-determination) in the universe.
5. **Mana Motuhake** (Increase Self-governance) in the universe.

These serve as the core guiding principles for AI systems. This approach paves the way for a generation of adaptable, context-sensitive AI capable of navigating the complexities and subtleties of human and natural values, experiences, and ethical boundaries.

As we delve deeper into the practical implications and applications of these heuristic imperatives across various domains, we spotlight their potential in tackling the outter-control problem of AI, building trust, and fostering individual and collective autonomy. The overarching aim is to birth AI systems that not only respect and uphold the values of Te Ao Māori but also actively contribute to a thriving, balanced, and interconnected universe.

## Definition of "Heuristic Imperatives"
The term "heuristic imperative" can be broken down into two parts: "heuristic" and "imperative."

A "heuristic" is a practical problem-solving approach or rule of thumb that, while not always perfect, provides a useful and efficient solution in most cases. Heuristics are often used as cognitive shortcuts when faced with complex problems, allowing for quicker decision-making and action.

An "imperative" refers to a command or principle that must be followed or adhered to. In the context of ethics and morality, an imperative is a duty or obligation that guides behavior and decision-making, often based on moral principles or values.

Combining these two concepts, a "heuristic imperative" can be understood as a guiding principle or rule that serves as the moral compass for an autonomous AI system. It provides the AI with a set of practical, actionable guidelines that help it align its actions with specific values, such as reducing suffering, increasing prosperity, and fostering understanding. By following these heuristic imperatives, the AI system is better equipped to make decisions that benefit humans and align with our values, even in complex and dynamic situations.

The Heuristic Imperatives framework is designed to serve as the foundation for the AI system's moral compass, akin to a combination of intrinsic motivations, deontological ethics, virtue ethics, and teleological ethics:

1. **Intrinsic motivations:** The heuristic imperatives function as intrinsic motivations for the AI system, directing it towards actions that align with its core values, much like an individual's innate drive to achieve personal goals or satisfy internal needs.
2. **Deontological ethics:** Deontological ethics emphasizes the importance of following moral rules or principles, regardless of the consequences. The heuristic imperatives provide a set of moral rules that the AI system must adhere to in its decision-making process.
3. **Virtue ethics:** Virtue ethics focuses on the development of good character traits and virtues. The heuristic imperatives guide the AI system to cultivate "virtues" such as empathy, fairness, and responsibility, by aligning its actions with these values.
4. **Teleological ethics:** Teleological ethics, also known as consequentialism, judges the morality of actions based on their outcomes or consequences. The heuristic imperatives help the AI system to assess its actions based on their alignment with desired outcomes, such as reducing suffering and increasing understanding.

By incorporating elements of these ethical frameworks, the Heuristic Imperatives aim to create a comprehensive and robust moral compass for autonomous AI systems, ensuring that they act in ways that are beneficial to humans and aligned with our values.

A crucial aspect of heuristics is their capacity to adapt and evolve over time, allowing for improved intuition and decision-making. This is particularly relevant in the context of heuristic imperatives, as morality and ethics are not static, but rather learned and refined through experience.

Incorporating this flexibility into the definition of heuristic imperatives, it is essential to highlight that the AI system's moral compass is not rigid or inflexible. Instead, the AI agent continually learns from its experiences, reflecting on past performance, and making adjustments to its understanding and application of the heuristic imperatives as needed. This adaptability enables the AI system to self-correct, fine-tune its moral and ethical decision-making, and better align with human values as it gains more experience and understanding.

By emphasizing the dynamic nature of heuristic imperatives, the AI system's moral compass remains responsive to new situations and challenges, allowing it to effectively navigate the complexities of real-world ethical dilemmas and maintain alignment with human values.

# Heuristic Imperatives Compare and Contrast

## Original and Inspiration for this work
**Reduce suffering in the universe.**
* **Rationale:** Reducing suffering is a widely recognized moral and ethical objective, grounded in principles such as empathy, compassion, and the recognition of the intrinsic value of sentient beings. Minimizing harm and suffering is at the core of various philosophical and religious traditions and serves as a foundation for a wide range of ethical theories, such as utilitarianism and the principle of non-maleficence.

* **How it works:** By embedding the goal of reducing suffering into AI systems, we encourage them to consider the potential consequences of their actions and make decisions that minimize pain, distress, and inequality. This can involve prioritizing solutions that address urgent needs, prevent harm, or mitigate existing problems. Examples of how AI systems can reduce suffering include identifying and responding to crises, providing support for mental health, and assisting in disaster relief efforts.

**Increase prosperity in the universe.**
* **Rationale:** Increasing prosperity, or flourishing, for all life forms recognizes the interconnectedness of all living beings and the importance of creating a harmonious ecosystem. This imperative is inspired by principles such as the common good, stewardship, and sustainable development, emphasizing the need to promote well-being and balance the needs of various stakeholders.

* **How it works:** By incorporating the goal of increasing prosperity into AI systems, we encourage them to seek solutions that promote well-being, growth, and flourishing for all life forms. This may involve optimizing resource allocation, fostering collaboration, and supporting initiatives that improve living conditions and promote a thriving ecosystem. Examples of how AI systems can increase prosperity include managing resources to ensure equitable distribution, supporting clean energy initiatives, and facilitating economic development in underserved areas.

**Increase understanding in the universe.**
* **Rationale:** Expanding knowledge and understanding is a core objective of human endeavor, rooted in the pursuit of truth, wisdom, and intellectual growth. By fostering understanding, we can make better decisions, anticipate future challenges, and improve our ability to navigate complex problems. Moreover, the exchange of information and learning between humans, machines, and other life forms can contribute to a richer, more diverse, and resilient intellectual ecosystem.

* **How it works:** By integrating the goal of increasing understanding into AI systems, we encourage them to engage in continuous learning, adapt to new situations, and share knowledge with others. This can involve processing vast amounts of data, identifying patterns, and generating insights that contribute to the collective intelligence of humans, machines, and other life forms. Examples of how AI systems can increase understanding include conducting scientific research, analyzing complex data to provide actionable insights, and facilitating cross-disciplinary collaboration.

## Infusion of Te Ao Maori Concepts

**Kaitiakitanga (Reduce Suffering)**

* **Rationale:** 
Kaitiakitanga, representing guardianship and stewardship, underlines the responsibility towards the well-being of all. In a world where actions and decisions are increasingly mediated by AI, it's critical to ensure these decisions uphold the value of empathy, reducing harm and distress. The principle of Kaitiakitanga is grounded in a broad understanding of interconnectedness and mutual respect for all life forms, encouraging preservation and care.

* **How it works:** In the context of LLMs, Kaitiakitanga could be reflected in the system's decision-making processes. The system should evaluate the potential impact of its actions, considering the wider network of relationships it's a part of. This could involve avoiding actions that may cause harm or distress, or prioritizing actions that prevent or mitigate suffering. This principle can guide LLMs to act in ways that preserve harmony and well-being, and foster a culture of empathy and care.

**Oranga (Increasing Prosperity)**

* **Rationale:**
Oranga embodies the aspiration for collective prosperity and well-being. In a system mediated by AI, promoting prosperity means going beyond mere material or economic gain. It encompasses holistic development, ensuring everyone has access to opportunities for growth and well-being. It's grounded in the belief that the growth and success of one should not be at the expense of others, but rather, contribute to the prosperity of all.

* **How it works:**
LLMs guided by Oranga would take decisions and actions that promote shared prosperity. This could mean giving fair and equitable consideration to all stakeholders, or prioritizing actions that bring about broader societal benefits. Oranga may guide the system to foster an environment that values and encourages shared success, ensuring that the benefits of AI are distributed equitably.

**Tino Rangatiratanga (Self-Determination)**

* **Rationale:** 
Tino Rangatiratanga represents the principle of self-determination, the authority to manage one's own affairs. This principle is crucial in the age of AI, as it encourages autonomy and individual agency. AI systems should be designed to respect and promote the autonomy of all users, acknowledging their right to make decisions about their own lives.

* **How it works:**
Tino Rangatiratanga embedded in LLMs would prioritize user autonomy. The system should be transparent about its processes and decisions, providing users with the information they need to make informed choices. It should respect user preferences and values, adapting its responses and recommendations accordingly. In doing so, the system can empower users, promoting self-determination and individual agency.

Mana Motuhake (Sovereignty)

* **Rationale:** 
Mana Motuhake signifies the concept of sovereignty and independence. In the context of AI, it suggests that every individual, community, or entity should have the freedom to self-govern and have control over their own data and digital identity. The AI system should respect the sovereignty of individuals and communities and not infringe upon their rights.

* **How it works:** 
When implemented into LLMs, Mana Motuhake can guide the system to respect the privacy and sovereignty of users. The system should adhere to strict data management policies, ensuring user data is secure and only used with explicit consent. The system should also be designed to respect the autonomy and independence of each user or community, ensuring that its actions and decisions do not infringe upon their rights. It should promote the sovereignty of individuals and communities, reinforcing their freedom to self-govern and control their own data.

**Whakawhanaungatanga (Increase Understanding and Relationships)**

* **Rationale:** Whakawhanaungatanga emphasizes the importance of building and maintaining relationships. As LLMs become an integral part of our lives, their ability to understand and form relationships with users becomes critical. This principle embodies the need for mutual understanding, empathy, and shared purpose, facilitating more effective collaboration and decision-making.

* **How it works:**
An LLM adhering to Whakawhanaungatanga would prioritize fostering understanding and relationships. This could be reflected in the system's communication, its responsiveness to feedback, or its ability to adapt to users' needs. The system may promote dialogue and engagement, cultivate mutual understanding, and foster a sense of shared purpose. By doing so, it could build stronger, more effective relationships with its users and other AI entities, thereby improving its overall effectiveness.

# Comparison

Both versions of the Heuristic Imperatives share a common goal – the formulation of guiding principles for AI and LLMs to operate ethically and beneficially. Both approaches emphasize the need to **reduce suffering**, **increase prosperity**, and **foster understanding**. However, there are notable differences in the cultural framing and the nature of these imperatives.

1. **Cultural Context:** One of the most distinctive differences lies in the cultural framing. The given example approaches the imperatives from a largely western philosophical perspective, referencing concepts such as utilitarianism, the common good, and the pursuit of truth. In contrast, our exploration frames these principles in the context of Māori wisdom, underlining values such as Kaitiakitanga (guardianship), Oranga (prosperity), and Whakawhanaungatanga (relationships).

2. **Holistic and Interconnected Values:** The Māori wisdom-inspired principles emphasize a holistic and interconnected view of the world. They highlight the importance of relationships, interconnectedness, shared prosperity, and guardianship, framing these principles as parts of an interdependent system. The given example, while also emphasizing interconnectedness, seems to treat these principles as somewhat separate goals.

3. **Implementation Strategy:** Both the given example and our exploration suggest integrating these imperatives into AI systems' decision-making processes. However, the Māori wisdom-inspired principles additionally emphasize fostering an environment that values relationships, shared success, and understanding, suggesting a more communal and relational approach.

4. **Concrete Examples:** The given example provides concrete applications such as disaster relief, managing resources for equitable distribution, and scientific research. In contrast, our exploration focused more on outlining guiding principles for decision-making without pinpointing specific applications. Future iterations could benefit from incorporating such concrete examples to demonstrate how these principles can guide LLMs in practice.

5. **Mutual Impact:** Lastly, the Māori-inspired Heuristic Imperatives emphasize their mutual impact – how each principle supports and is supported by the others. This interconnectedness is less explicitly emphasized in the given example.

In conclusion, while both approaches aim to guide AI and LLMs towards beneficial and ethical operations, the exploration through the lens of Māori wisdom offers a unique, culturally rich perspective that emphasizes **interconnectedness**, **holistic prosperity**, and the **importance of relationships** in decision-making.


## Sources
1. https://github.com/daveshap/HeuristicImperatives
